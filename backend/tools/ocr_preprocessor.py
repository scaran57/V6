#!/usr/bin/env python3
"""
OCR Preprocessor - Nettoyage et optimisation d'images pour amÃ©liorer l'OCR
GÃ¨re les overlays, le bruit, et optimise le contraste pour extraire le texte.

Techniques implÃ©mentÃ©es :
- Suppression du bruit par filtrage gaussien
- Recadrage automatique des zones texte
- Conversion noir et blanc avec threshold adaptatif
- DÃ©tection et suppression d'overlays
- AmÃ©lioration du contraste (CLAHE)
"""

import cv2
import numpy as np
import logging
from typing import Tuple, List, Optional
from pathlib import Path

logger = logging.getLogger(__name__)


def remove_overlays(img: np.ndarray) -> np.ndarray:
    """
    Supprime les overlays colorÃ©s (scores, logos, UI) de l'image.
    
    StratÃ©gie :
    - DÃ©tecte les zones avec saturation Ã©levÃ©e (overlays colorÃ©s)
    - Les remplace par du blanc/gris pour ne pas perturber l'OCR
    
    Args:
        img: Image BGR (OpenCV format)
    
    Returns:
        Image nettoyÃ©e
    """
    # Convertir en HSV pour dÃ©tecter les zones colorÃ©es
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    
    # Masque pour les zones trÃ¨s saturÃ©es (overlays colorÃ©s)
    # Saturation > 100, Value > 50
    lower_overlay = np.array([0, 100, 50])
    upper_overlay = np.array([180, 255, 255])
    mask = cv2.inRange(hsv, lower_overlay, upper_overlay)
    
    # Dilater le masque pour capturer toute la zone overlay
    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.dilate(mask, kernel, iterations=2)
    
    # Remplacer les zones overlay par du blanc
    img_clean = img.copy()
    img_clean[mask > 0] = [255, 255, 255]
    
    logger.debug(f"Overlays supprimÃ©s : {np.sum(mask > 0)} pixels modifiÃ©s")
    
    return img_clean


def auto_crop_text_regions(img: np.ndarray) -> np.ndarray:
    """
    Recadrage automatique pour garder uniquement les zones de texte.
    
    StratÃ©gie :
    - DÃ©tecte les zones avec beaucoup de contours (texte)
    - Garde la rÃ©gion centrale contenant le plus de texte
    - Coupe les marges vides (header/footer)
    
    Args:
        img: Image BGR
    
    Returns:
        Image recadrÃ©e
    """
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # DÃ©tection de contours pour trouver les zones de texte
    edges = cv2.Canny(gray, 50, 150)
    
    # Trouver les contours
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        logger.warning("Aucun contour dÃ©tectÃ©, pas de recadrage")
        return img
    
    # Trouver le rectangle englobant de tous les contours
    x_min, y_min = img.shape[1], img.shape[0]
    x_max, y_max = 0, 0
    
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        x_min = min(x_min, x)
        y_min = min(y_min, y)
        x_max = max(x_max, x + w)
        y_max = max(y_max, y + h)
    
    # Ajouter une marge de 10 pixels
    margin = 10
    x_min = max(0, x_min - margin)
    y_min = max(0, y_min - margin)
    x_max = min(img.shape[1], x_max + margin)
    y_max = min(img.shape[0], y_max + margin)
    
    # Recadrer
    cropped = img[y_min:y_max, x_min:x_max]
    
    logger.debug(f"Image recadrÃ©e : {img.shape} â†’ {cropped.shape}")
    
    return cropped


def enhance_contrast(img: np.ndarray) -> np.ndarray:
    """
    AmÃ©liore le contraste de l'image avec CLAHE (Contrast Limited Adaptive Histogram Equalization).
    
    Args:
        img: Image BGR ou grayscale
    
    Returns:
        Image avec contraste amÃ©liorÃ©
    """
    # Convertir en niveaux de gris si nÃ©cessaire
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img.copy()
    
    # Appliquer CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    
    logger.debug("Contraste amÃ©liorÃ© avec CLAHE")
    
    return enhanced


def adaptive_threshold(img: np.ndarray) -> np.ndarray:
    """
    Convertit l'image en noir et blanc avec threshold adaptatif.
    Meilleur que le threshold global pour gÃ©rer les variations d'Ã©clairage.
    
    Args:
        img: Image grayscale
    
    Returns:
        Image binaire (noir et blanc)
    """
    # Appliquer un flou gaussien pour rÃ©duire le bruit
    blurred = cv2.GaussianBlur(img, (3, 3), 0)
    
    # Threshold adaptatif
    binary = cv2.adaptiveThreshold(
        blurred, 
        255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        11,  # Taille du voisinage
        2    # Constante soustraite
    )
    
    logger.debug("Threshold adaptatif appliquÃ©")
    
    return binary


def denoise_image(img: np.ndarray) -> np.ndarray:
    """
    Supprime le bruit de l'image avec un filtre non-local means.
    
    Args:
        img: Image BGR ou grayscale
    
    Returns:
        Image dÃ©bruitÃ©e
    """
    if len(img.shape) == 3:
        # Image couleur
        denoised = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)
    else:
        # Image grayscale
        denoised = cv2.fastNlMeansDenoising(img, None, 10, 7, 21)
    
    logger.debug("Bruit supprimÃ©")
    
    return denoised


def preprocess_for_ocr(
    img_path: str,
    remove_overlay: bool = True,
    auto_crop: bool = True,
    enhance: bool = True,
    denoise: bool = False,
    output_path: Optional[str] = None
) -> np.ndarray:
    """
    Pipeline complet de prÃ©traitement pour optimiser l'OCR.
    
    Args:
        img_path: Chemin de l'image Ã  traiter
        remove_overlay: Supprimer les overlays colorÃ©s
        auto_crop: Recadrer automatiquement les zones de texte
        enhance: AmÃ©liorer le contraste
        denoise: Supprimer le bruit (lent)
        output_path: Chemin pour sauvegarder l'image prÃ©traitÃ©e (optionnel)
    
    Returns:
        Image prÃ©traitÃ©e (grayscale)
    """
    logger.info(f"ğŸ”§ PrÃ©traitement OCR : {img_path}")
    
    # Charger l'image
    img = cv2.imread(img_path)
    
    if img is None:
        raise ValueError(f"Impossible de charger l'image : {img_path}")
    
    logger.debug(f"Image chargÃ©e : {img.shape}")
    
    # Ã‰tape 1 : Supprimer les overlays
    if remove_overlay:
        img = remove_overlays(img)
    
    # Ã‰tape 2 : Recadrage automatique
    if auto_crop:
        img = auto_crop_text_regions(img)
    
    # Ã‰tape 3 : DÃ©bruitage (optionnel, lent)
    if denoise:
        img = denoise_image(img)
    
    # Ã‰tape 4 : Conversion en niveaux de gris
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img
    
    # Ã‰tape 5 : AmÃ©lioration du contraste
    if enhance:
        gray = enhance_contrast(gray)
    
    # Ã‰tape 6 : Threshold adaptatif
    binary = adaptive_threshold(gray)
    
    # Sauvegarder si demandÃ©
    if output_path:
        cv2.imwrite(output_path, binary)
        logger.info(f"âœ… Image prÃ©traitÃ©e sauvegardÃ©e : {output_path}")
    
    logger.info(f"âœ… PrÃ©traitement terminÃ© : {img.shape} â†’ {binary.shape}")
    
    return binary


def preprocess_multiple_variants(img_path: str, output_dir: Optional[str] = None) -> List[Tuple[str, np.ndarray]]:
    """
    CrÃ©e plusieurs variantes prÃ©traitÃ©es de l'image pour maximiser les chances de bon OCR.
    
    Args:
        img_path: Chemin de l'image source
        output_dir: Dossier pour sauvegarder les variantes (optionnel)
    
    Returns:
        Liste de tuples (nom_variante, image_prÃ©traitÃ©e)
    """
    logger.info(f"ğŸ”„ GÃ©nÃ©ration de variantes pour : {img_path}")
    
    variants = []
    
    # Variante 1 : Traitement complet
    try:
        v1 = preprocess_for_ocr(img_path, remove_overlay=True, auto_crop=True, enhance=True, denoise=False)
        variants.append(("full_processing", v1))
    except Exception as e:
        logger.error(f"Erreur variante 1: {e}")
    
    # Variante 2 : Sans recadrage (garde tout)
    try:
        v2 = preprocess_for_ocr(img_path, remove_overlay=True, auto_crop=False, enhance=True, denoise=False)
        variants.append(("no_crop", v2))
    except Exception as e:
        logger.error(f"Erreur variante 2: {e}")
    
    # Variante 3 : Minimal (juste threshold)
    try:
        v3 = preprocess_for_ocr(img_path, remove_overlay=False, auto_crop=False, enhance=True, denoise=False)
        variants.append(("minimal", v3))
    except Exception as e:
        logger.error(f"Erreur variante 3: {e}")
    
    # Sauvegarder les variantes si demandÃ©
    if output_dir:
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        base_name = Path(img_path).stem
        
        for i, (variant_name, img) in enumerate(variants):
            output_path = Path(output_dir) / f"{base_name}_{variant_name}.png"
            cv2.imwrite(str(output_path), img)
            logger.debug(f"Variante sauvegardÃ©e : {output_path}")
    
    logger.info(f"âœ… {len(variants)} variantes gÃ©nÃ©rÃ©es")
    
    return variants


# Test du module
if __name__ == "__main__":
    import sys
    
    logging.basicConfig(level=logging.DEBUG)
    
    if len(sys.argv) < 2:
        print("Usage: python ocr_preprocessor.py <image_path>")
        sys.exit(1)
    
    img_path = sys.argv[1]
    
    print("=" * 70)
    print("TEST OCR PREPROCESSOR")
    print("=" * 70)
    print()
    
    # Test prÃ©traitement simple
    print("ğŸ“¸ Test 1: PrÃ©traitement simple")
    try:
        processed = preprocess_for_ocr(img_path, output_path="/tmp/preprocessed_test.png")
        print(f"âœ… Image prÃ©traitÃ©e : {processed.shape}")
        print(f"   SauvegardÃ©e : /tmp/preprocessed_test.png")
    except Exception as e:
        print(f"âŒ Erreur : {e}")
    
    print()
    
    # Test variantes multiples
    print("ğŸ“¸ Test 2: GÃ©nÃ©ration de variantes")
    try:
        variants = preprocess_multiple_variants(img_path, output_dir="/tmp/ocr_variants")
        print(f"âœ… {len(variants)} variantes gÃ©nÃ©rÃ©es")
        print("   SauvegardÃ©es dans : /tmp/ocr_variants/")
    except Exception as e:
        print(f"âŒ Erreur : {e}")
    
    print()
    print("=" * 70)
