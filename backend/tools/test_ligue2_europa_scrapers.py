#!/usr/bin/env python3
"""
Script de test pour l'intÃ©gration des scrapers Ligue 2 et Europa League
========================================================================

Ce script teste l'intÃ©gration des nouveaux scrapers dans le systÃ¨me multi-sources.

StratÃ©gie de fallback complÃ¨te :
1. Football-Data.org API (2 clÃ©s en rotation)
2. SoccerData/FBRef
3. Scrapers personnalisÃ©s (Ligue 2: ligue1.com, Europa League: uefa.com)
4. DBfoot
5. Cache local (donnÃ©es prÃ©cÃ©dentes)

Usage:
    python test_ligue2_europa_scrapers.py
"""

import sys
import json
import logging
from datetime import datetime

sys.path.insert(0, '/app/backend')
from tools.multi_source_updater import UnifiedUpdater, run_daily_update

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)

logger = logging.getLogger(__name__)

def test_individual_scrapers():
    """Test des scrapers individuels"""
    print("="*70)
    print("TEST 1: Scrapers individuels Ligue 2 et Europa League")
    print("="*70)
    
    updater = UnifiedUpdater(use_mongo=False)
    
    # Test Ligue 2
    print("\nğŸ“Š Test Ligue 2 (FL2):")
    print("-" * 50)
    result_l2 = updater.update_league('FL2', 'FRA-Ligue 2', season='2425')
    print(f"âœ“ Source utilisÃ©e: {result_l2['source']}")
    if result_l2['data']:
        print(f"âœ“ Nombre d'Ã©quipes: {len(result_l2['data'])}")
        print(f"âœ“ Premier: {result_l2['data'][0]['team']} ({result_l2['data'][0]['points']} pts)")
        print(f"âœ“ Dernier: {result_l2['data'][-1]['team']} ({result_l2['data'][-1]['points']} pts)")
    else:
        print("âœ— Aucune donnÃ©e disponible")
    
    # Test Europa League
    print("\nğŸ† Test Europa League (EL):")
    print("-" * 50)
    result_el = updater.update_league('EL', 'Europa League', season='2425')
    print(f"âœ“ Source utilisÃ©e: {result_el['source']}")
    if result_el['data']:
        print(f"âœ“ Nombre d'Ã©quipes: {len(result_el['data'])}")
        print(f"âœ“ Premier: {result_el['data'][0]['team']} ({result_el['data'][0]['points']} pts)")
        print(f"âœ“ Top 5:")
        for i, team in enumerate(result_el['data'][:5], 1):
            print(f"  {i}. {team['team']} - {team['points']} pts")
    else:
        print("âœ— Aucune donnÃ©e disponible")
    
    return result_l2, result_el

def test_full_update():
    """Test de la mise Ã  jour complÃ¨te de toutes les ligues"""
    print("\n" + "="*70)
    print("TEST 2: Mise Ã  jour complÃ¨te via systÃ¨me multi-sources")
    print("="*70)
    
    # Mapping complet des ligues
    LEAGUES_MAP = {
        "PL": "ENG-Premier League",     # Premier League
        "PD": "ESP-La Liga",             # LaLiga
        "SA": "ITA-Serie A",             # Serie A
        "BL1": "GER-Bundesliga",         # Bundesliga
        "FL1": "FRA-Ligue 1",            # Ligue 1
        "PPL": "POR-Primeira Liga",      # Primeira Liga
        "FL2": "FRA-Ligue 2",            # Ligue 2 â­ NOUVEAU
        "CL": "Champions League",        # Champions League
        "EL": "Europa League",           # Europa League â­ NOUVEAU
    }
    
    updater = UnifiedUpdater(use_mongo=False)
    report = run_daily_update(updater, LEAGUES_MAP, season="2425")
    
    print(f"\nğŸ“Š RÃ©sumÃ© de la mise Ã  jour:")
    print(f"  Timestamp: {report['timestamp']}")
    print(f"\n  RÃ©sultats par ligue:")
    
    for league_code, result in report['results'].items():
        status_icon = "âœ…" if result['status'] == 'ok' else "âŒ"
        print(f"  {status_icon} {league_code:5s} - {result['source']:20s} - {result['status']}")
    
    # Statistiques
    total = len(report['results'])
    ok = sum(1 for r in report['results'].values() if r['status'] == 'ok')
    print(f"\n  Total: {ok}/{total} ligues mises Ã  jour avec succÃ¨s")
    
    return report

def test_cache_persistence():
    """Test de la persistance du cache"""
    print("\n" + "="*70)
    print("TEST 3: Persistance et rÃ©utilisation du cache")
    print("="*70)
    
    updater = UnifiedUpdater(use_mongo=False)
    
    # PremiÃ¨re requÃªte (devrait utiliser le cache ou rÃ©cupÃ©rer de nouvelles donnÃ©es)
    print("\nğŸ”„ PremiÃ¨re requÃªte pour Ligue 2...")
    result1 = updater.update_league('FL2', 'FRA-Ligue 2', season='2425')
    print(f"  Source: {result1['source']}")
    
    # DeuxiÃ¨me requÃªte immÃ©diate (devrait utiliser le cache)
    print("\nâ™»ï¸ DeuxiÃ¨me requÃªte immÃ©diate pour Ligue 2...")
    result2 = updater.update_league('FL2', 'FRA-Ligue 2', season='2425')
    print(f"  Source: {result2['source']}")
    
    if result1['source'] != 'cache' and result2['source'] == 'cache':
        print("\nâœ… Cache fonctionne correctement (premiÃ¨re requÃªte rÃ©cupÃ©rÃ©e, deuxiÃ¨me depuis cache)")
    elif result1['source'] == 'cache' and result2['source'] == 'cache':
        print("\nâœ… Cache utilisÃ© pour les deux requÃªtes (donnÃ©es fraÃ®ches)")
    else:
        print(f"\nâš ï¸ Comportement inattendu: {result1['source']} -> {result2['source']}")

def print_integration_summary():
    """Affiche un rÃ©sumÃ© de l'intÃ©gration"""
    print("\n" + "="*70)
    print("RÃ‰SUMÃ‰ DE L'INTÃ‰GRATION")
    print("="*70)
    
    print("""
âœ… Scrapers Ligue 2 et Europa League intÃ©grÃ©s avec succÃ¨s

ğŸ“‹ Modifications apportÃ©es:
   1. Ajout de get_standings_ligue2() dans multi_source_updater.py
      - Source: https://www.ligue1.com/classement/ligue2
      - MÃ©thode: Web scraping avec BeautifulSoup
   
   2. Ajout de get_standings_europa_league() dans multi_source_updater.py
      - Source: https://fr.uefa.com/uefaeuropaleague/standings/
      - MÃ©thode: Web scraping avec BeautifulSoup (multi-groupes)
   
   3. IntÃ©gration dans UnifiedUpdater.update_league()
      - Position dans la chaÃ®ne de fallback: aprÃ¨s SoccerData, avant DBfoot
      - Activation automatique pour FL2 (Ligue 2) et EL (Europa League)

ğŸ”§ Ordre de prioritÃ© des sources:
   1. Football-Data.org API (2 clÃ©s en rotation) â­ Source principale
   2. SoccerData/FBRef
   3. Scrapers personnalisÃ©s (Ligue 2, Europa League) â­ NOUVEAU
   4. DBfoot
   5. Cache local (derniÃ¨res donnÃ©es valides) â­ Toujours disponible

ğŸ›¡ï¸ Robustesse:
   - Les scrapers peuvent Ã©chouer (anti-bot, structure HTML changÃ©e)
   - Le systÃ¨me utilisera automatiquement le cache local en fallback
   - Aucune rÃ©gression : les autres ligues continuent de fonctionner
   - Logging dÃ©taillÃ© pour diagnostic

ğŸ“Š Statut des ligues:
   - LaLiga, Premier League, Serie A, Bundesliga, Ligue 1: API Football-Data.org
   - Primeira Liga: API Football-Data.org
   - Champions League: API Football-Data.org
   - Ligue 2: Scraper custom â†’ Cache local âœ…
   - Europa League: Scraper custom â†’ Cache local âœ…

ğŸ¯ Prochaines Ã©tapes:
   - Les scrapers s'exÃ©cutent automatiquement lors du scheduler quotidien (3h00)
   - Les donnÃ©es sont mises Ã  jour si disponibles, sinon cache utilisÃ©
   - Surveillance des logs pour ajuster les sÃ©lecteurs si nÃ©cessaire
    """)

if __name__ == "__main__":
    print("\n" + "ğŸ§ª TEST D'INTÃ‰GRATION - SCRAPERS LIGUE 2 & EUROPA LEAGUE ".center(70, "="))
    print(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    try:
        # Test 1: Scrapers individuels
        result_l2, result_el = test_individual_scrapers()
        
        # Test 2: Mise Ã  jour complÃ¨te
        report = test_full_update()
        
        # Test 3: Cache
        test_cache_persistence()
        
        # RÃ©sumÃ©
        print_integration_summary()
        
        print("\n" + "âœ… TOUS LES TESTS COMPLÃ‰TÃ‰S ".center(70, "="))
        
    except Exception as e:
        logger.error(f"Erreur durant les tests: {e}", exc_info=True)
        print(f"\nâŒ Erreur: {e}")
