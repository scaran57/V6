"""
Module de calcul des probabilit√©s de scores
Bas√© sur l'algorithme original avec pond√©ration Poisson et correction adaptative des nuls
+ Apprentissage par √©quipe avec historique des 5 derniers matchs
+ NOUVEAU: Algorithme combin√© Poisson + ImpliedOdds avec smoothing de voisinage
+ NOUVEAU: Int√©gration coefficient de classement de ligue
"""
import math
import logging
import json
import os
from collections import defaultdict

logger = logging.getLogger(__name__)

# Import du syst√®me de coefficient de ligue
try:
    import league_coeff
    LEAGUE_COEFF_AVAILABLE = True
except ImportError:
    LEAGUE_COEFF_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Module league_coeff non disponible")

# ====== Param√®tres calibrables pour l'algorithme combin√© ======
MAX_GOALS = 5            # clamp goals per side (0..5)
ALPHA = 1.0              # force de la gaussienne sur diff (avant: 0.4) -> augmenter pour +discrimination
BLEND_BETA = 0.7         # poids Poisson vs ImpliedOdds (0..1). 0.7 = 70% Poisson, 30% odds
EPS = 1e-9               # lissage pour √©viter 0
# ===============================================================


# ============================================================================
# üéØ MODULE : POND√âRATION PAR COTE BOOKMAKER (AJOUT OFFICIEL)
# ============================================================================

def adjust_score_weight_by_odds(odds: float, base_weight: float = 1.0) -> float:
    """
    Ajuste le poids d'un score selon la cote bookmaker.
    Cette fonction est appel√©e apr√®s OCR et avant le calcul principal.
    
    Logique:
    - Cotes tr√®s basses (‚â§ 1.8): trop √©videntes ‚Üí r√©duction 15%
    - Cotes moyennes (1.8-4.0): zone neutre ‚Üí pas d'ajustement
    - Cotes int√©ressantes (4.0-8.0): value bet ‚Üí augmentation 10%
    - Cotes √©lev√©es (8.0-15.0): peu probable ‚Üí r√©duction 10%
    - Cotes extr√™mes (> 15.0): tr√®s peu probable ‚Üí r√©duction 20%
    
    Args:
        odds: Cote du bookmaker
        base_weight: Poids de base (d√©faut: 1.0)
        
    Returns:
        float: Poids ajust√©
    """
    if odds <= 1.8:
        return base_weight * 0.85   # Trop √©vident ‚Üí -15%
    elif 1.8 < odds <= 4.0:
        return base_weight          # Zone neutre
    elif 4.0 < odds <= 8.0:
        return base_weight * 1.10   # L√©g√®re value ‚Üí +10%
    elif 8.0 < odds <= 15.0:
        return base_weight * 0.90   # Peu probable ‚Üí -10%
    else:
        return base_weight * 0.80   # Score extr√™me ‚Üí -20%


def process_scores_with_odds(extracted_scores: dict, enable_odds_weighting: bool = True) -> dict:
    """
    Transforme les scores extraits (OCR) en pond√©rations probabilistes ajust√©es.
    
    Cette fonction peut √™tre utilis√©e AVANT calculate_probabilities pour
    pr√©ajuster les probabilit√©s selon la confiance du bookmaker.
    
    Args:
        extracted_scores: dict {"score": odds} ou list [{"score": "X-Y", "odds": Z}]
        enable_odds_weighting: Activer/d√©sactiver la pond√©ration (d√©faut: True)
        
    Returns:
        dict: Probabilit√©s normalis√©es √† 100% {score: probability}
    """
    # Conversion si format liste
    if isinstance(extracted_scores, list):
        scores_dict = {item["score"]: item["odds"] for item in extracted_scores}
    else:
        scores_dict = extracted_scores
    
    weighted_scores = {}
    
    for score, odds in scores_dict.items():
        try:
            odds_val = float(odds)
        except (ValueError, TypeError):
            logger.warning(f"Cote invalide pour {score}: {odds}")
            continue
        
        # Application de la pond√©ration si activ√©e
        if enable_odds_weighting:
            weight = adjust_score_weight_by_odds(odds_val)
            logger.debug(f"Score {score}: cote={odds_val:.2f}, poids ajust√©={weight:.3f}")
        else:
            weight = 1.0
        
        weighted_scores[score] = weight
    
    # Normalisation √† 100%
    total_weight = sum(weighted_scores.values())
    if total_weight == 0:
        logger.warning("Poids total = 0, impossible de normaliser")
        return {s: 0 for s in weighted_scores}
    
    probabilities = {s: (w / total_weight) * 100 for s, w in weighted_scores.items()}
    
    # Tri par probabilit√© d√©croissante
    sorted_probs = dict(sorted(probabilities.items(), key=lambda x: x[1], reverse=True))
    
    logger.info(f"üéØ Pond√©ration par cotes: {len(sorted_probs)} scores trait√©s")
    if sorted_probs:
        top_score = list(sorted_probs.items())[0]
        logger.info(f"   Top score apr√®s pond√©ration: {top_score[0]} ({top_score[1]:.2f}%)")
    
    return sorted_probs


# ============================================================================
# üß© EXEMPLE D'UTILISATION (COMPATIBILIT√â TOTALE)
# ============================================================================
# 
# Apr√®s l'OCR, vous pouvez:
#
# Option 1: Utiliser directement process_scores_with_odds (pond√©ration uniquement)
# extracted_scores = {"2-4": 5.5, "4-2": 7.6, "2-0": 3.2, "2-3": 6.8, "1-0": 2.1}
# probabilities = process_scores_with_odds(extracted_scores)
# 
# Option 2: Utiliser calculate_probabilities (algorithme complet avec Poisson)
# result = calculate_probabilities(extracted_scores, diff_expected=2)
#
# Option 3: Combiner les deux (recommand√© pour meilleure pr√©cision)
# pre_weighted = process_scores_with_odds(extracted_scores)
# result = calculate_probabilities(extracted_scores, diff_expected=2)
#
# ============================================================================


def calculate_confidence(probabilities: dict, best_score: str) -> float:
    """
    Calcule un indicateur de confiance global de la pr√©diction.
    
    La confiance est bas√©e sur:
    - La probabilit√© du meilleur score
    - L'√©cart avec le 2√®me score
    - La distribution globale des probabilit√©s
    
    Args:
        probabilities: Dict des probabilit√©s calcul√©es
        best_score: Score le plus probable
        
    Returns:
        float: Score de confiance entre 0.0 et 1.0
        
    Exemples:
        - Confiance √©lev√©e (0.8-1.0): Un score domine clairement
        - Confiance moyenne (0.5-0.8): Plusieurs scores possibles
        - Confiance faible (0.0-0.5): Distribution tr√®s √©parse
    """
    if not probabilities or best_score not in probabilities:
        return 0.0
    
    sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)
    
    # Probabilit√© du meilleur score (normalis√©e sur 100)
    best_prob = sorted_probs[0][1] / 100.0
    
    # √âcart avec le 2√®me score
    if len(sorted_probs) > 1:
        second_prob = sorted_probs[1][1] / 100.0
        gap = best_prob - second_prob
    else:
        gap = best_prob
    
    # Formule de confiance combin√©e (inspir√©e du vFinal avec ajustements)
    # Facteur 1: Probabilit√© du meilleur (poids 60%)
    # Facteur 2: √âcart avec le 2√®me (poids 40%)
    confidence = (best_prob * 0.6) + (gap * 0.4)
    
    # Facteur d'ajustement si la proba du meilleur est tr√®s √©lev√©e
    if best_prob > 0.25:  # Plus de 25%
        confidence *= 1.2
    
    # Limitation entre 0 et 1
    confidence = min(1.0, max(0.0, confidence))
    
    return confidence


def calculate_probabilities(scores, diff_expected=2, use_odds_weighting=False):
    """
    Calcule les probabilit√©s corrig√©es de chaque score selon l'algorithme original
    avec pond√©ration Poisson simplifi√©e et ajustement adaptatif des matchs nuls.
    
    Args:
        scores: dict {score: odds} ou list [{"score": "X-Y", "odds": Z}]
        diff_expected: diff√©rence de buts attendue (d√©faut: 2)
        use_odds_weighting: Appliquer la pond√©ration par cote AVANT le calcul (d√©faut: False)
    
    Returns:
        dict avec mostProbableScore et probabilities
        
    Note:
        Si use_odds_weighting=True, les scores seront pr√©pond√©r√©s selon les cotes
        bookmaker avant d'appliquer l'algorithme Poisson et la correction des nuls.
    """
    
    # üß© √âtape 1 : V√©rification et normalisation des donn√©es
    if not scores:
        logger.warning("Aucune donn√©e pour la pr√©diction")
        return {"mostProbableScore": "Aucune donn√©e", "probabilities": {}}
    
    # Conversion si format liste (venant de l'OCR)
    if isinstance(scores, list):
        scores_dict = {item["score"]: item["odds"] for item in scores}
    else:
        scores_dict = scores
    
    logger.info(f"Calcul probabilit√©s pour {len(scores_dict)} scores, diffExpected={diff_expected}, odds_weighting={use_odds_weighting}")
    
    # üéØ Pond√©ration par cotes si activ√©e
    if use_odds_weighting:
        logger.info("‚öôÔ∏è Application de la pond√©ration par cote bookmaker...")
        odds_weights = {}
        for score, odds in scores_dict.items():
            try:
                odds_val = float(odds)
                odds_weights[score] = adjust_score_weight_by_odds(odds_val)
            except (ValueError, TypeError):
                odds_weights[score] = 1.0
    else:
        odds_weights = {score: 1.0 for score in scores_dict.keys()}
    
    # Normalisation de base (1 / cote) √ó poids cote
    raw_probs = {}
    for score, odds in scores_dict.items():
        try:
            if float(odds) > 0:
                base_prob = 1.0 / float(odds)
                # Appliquer le poids de la cote si activ√©
                raw_probs[score] = base_prob * odds_weights.get(score, 1.0)
        except (ValueError, TypeError):
            logger.warning(f"Cote invalide pour {score}: {odds}")
            continue
    
    if not raw_probs:
        return {"mostProbableScore": "Aucune donn√©e", "probabilities": {}}
    
    sum_raw = sum(raw_probs.values())
    normalized = {k: v / sum_raw for k, v in raw_probs.items()}
    
    logger.info(f"Probabilit√©s normalis√©es: {normalized}")

    # üß† √âtape 2 : Pond√©ration Poisson (comme code Kotlin original)
    weighted = {}
    for score, p in normalized.items():
        if score == "Autre" or "-" not in score:
            weighted[score] = p
            continue
            
        parts = score.split("-")
        if len(parts) == 2:
            try:
                home = int(parts[0])
                away = int(parts[1])
                diff = abs(away - home)
                adjusted_diff = diff_expected + 1 if diff_expected > 2 else diff_expected
                weight = math.exp(-0.4 * (diff - adjusted_diff) ** 2)
                weighted[score] = p * weight
                logger.info(f"Score {score}: diff={diff}, weight={weight:.3f}, weighted={p * weight:.4f}")
            except ValueError:
                weighted[score] = p
                continue
        else:
            weighted[score] = p

    # Normalisation finale
    total = sum(weighted.values())
    final_probabilities = {k: (v / total) * 100 for k, v in weighted.items()}

    # üéØ √âtape 3 : Correction adaptative des nuls extr√™mes
    logger.info("üîß Application correction adaptative des nuls...")
    for score, p in list(final_probabilities.items()):
        if score == "Autre" or "-" not in score:
            continue
            
        try:
            home, away = map(int, score.split("-"))
            if home == away:  # Score nul
                if home >= 3:
                    # R√©duction forte pour 3-3, 4-4, etc.
                    final_probabilities[score] *= 0.75
                    logger.info(f"  {score}: r√©duit de 25% (nul √©lev√©)")
                elif home == 2:
                    # L√©g√®re r√©duction pour 2-2
                    final_probabilities[score] *= 0.95
                    logger.info(f"  {score}: r√©duit de 5% (2-2)")
                # 0-0 et 1-1 pas touch√©s
        except ValueError:
            continue

    # Recalcule apr√®s correction
    total_adj = sum(final_probabilities.values())
    final_probabilities = {k: (v / total_adj) * 100 for k, v in final_probabilities.items()}

    # üîç √âtape 4 : Score le plus probable
    most_probable = max(final_probabilities, key=final_probabilities.get, default="Inconnu")
    
    logger.info(f"üèÜ Score le plus probable: {most_probable} ({final_probabilities.get(most_probable, 0):.2f}%)")

    # üéØ √âtape 5 : Calcul de la confiance globale
    confidence = calculate_confidence(final_probabilities, most_probable)
    logger.info(f"üíØ Confiance globale: {confidence:.2%}")

    # üîÅ √âtape 6 : Retour format√©
    return {
        "mostProbableScore": most_probable,
        "probabilities": {k: round(v, 2) for k, v in final_probabilities.items()},
        "confidence": round(confidence, 3)
    }


# ============================================================================
# === Module Local Learning Compact - Apprentissage par √âquipe ===
# ============================================================================
json_path = "/app/data/teams_data.json"

def _load_data():
    """Charge les donn√©es des √©quipes"""
    if not os.path.exists(json_path):
        os.makedirs(os.path.dirname(json_path), exist_ok=True)
        with open(json_path, "w") as f: 
            json.dump({}, f)
    with open(json_path, "r") as f: 
        return json.load(f)

def _save_data(d): 
    """Sauvegarde les donn√©es des √©quipes"""
    with open(json_path, "w") as f: 
        json.dump(d, f, indent=2)

def update_team_results(team, gf, ga):
    """
    Enregistre le r√©sultat d'un match pour une √©quipe.
    Garde les 5 derniers matchs seulement.
    
    Args:
        team: Nom de l'√©quipe
        gf: Goals For (buts marqu√©s)
        ga: Goals Against (buts encaiss√©s)
    """
    d = _load_data()
    d.setdefault(team, []).append([gf, ga])
    d[team] = d[team][-5:]  # garde les 5 derniers matchs
    _save_data(d)
    logger.info(f"üìù Stats mises √† jour pour {team}: {gf}-{ga}")

def get_team_stats(team):
    """
    R√©cup√®re les statistiques moyennes d'une √©quipe.
    
    Args:
        team: Nom de l'√©quipe
        
    Returns:
        tuple: (moyenne buts marqu√©s, moyenne buts encaiss√©s)
    """
    d = _load_data()
    if team not in d or not d[team]: 
        return (1.5, 1.5)  # Valeurs par d√©faut
    
    gf = sum(x[0] for x in d[team]) / len(d[team])
    ga = sum(x[1] for x in d[team]) / len(d[team])
    return round(gf, 2), round(ga, 2)

def adjust_diff_expected(diff, home, away):
    """
    Ajuste le diffExpected en fonction des statistiques des √©quipes.
    
    Args:
        diff: diffExpected actuel
        home: Nom de l'√©quipe domicile
        away: Nom de l'√©quipe ext√©rieur
        
    Returns:
        float: diffExpected ajust√© entre 0 et 3
    """
    h_for, h_against = get_team_stats(home)
    a_for, a_against = get_team_stats(away)
    
    # Calcul de l'ajustement bas√© sur la force offensive et d√©fensive
    adj = ((h_for - a_against) - (a_for - h_against)) / 2
    
    # Ajuster et limiter entre 0 et 3
    new_diff = max(0, min(3, round(diff + adj, 2)))
    
    logger.info(f"‚öôÔ∏è Ajustement diffExpected: {diff} ‚Üí {new_diff} (home: {home}, away: {away})")
    logger.info(f"   {home}: {h_for} buts/match, {h_against} encaiss√©s/match")
    logger.info(f"   {away}: {a_for} buts/match, {a_against} encaiss√©s/match")
    
    return new_diff

def get_all_teams_stats():
    """R√©cup√®re les statistiques de toutes les √©quipes"""
    return _load_data()


# ============================================================================
# === NOUVEL ALGORITHME COMBIN√â - predict_combined ===
# ============================================================================

def implied_prob_from_odds(odds):
    """
    Convertit une cote (ex: 5.5) en probabilit√© implicite (non normalis√©e).
    On laisse 1/odds ; la normalisation se fait apr√®s.
    """
    try:
        o = float(odds)
        if o <= 0:
            return 0.0
        return 1.0 / o
    except:
        return 0.0

def poisson_pmf(k, lam):
    """PMF de Poisson"""
    # limiter overflow
    if lam <= 0:
        return 0.0 if k > 0 else 1.0
    try:
        return (lam**k) * math.exp(-lam) / math.factorial(k)
    except OverflowError:
        return 0.0

def compute_team_lambdas(teamA_stats, teamB_stats, global_scale=1.0):
    """
    Calcule lambda_home, lambda_away √† partir des stats (avg scored/conceded).
    teamX_stats: dict {'avg_goals_scored':float, 'avg_goals_conceded':float}
    global_scale: multiplicateur si tu veux augmenter tendance aux buts
    """
    # estimation simple : moyenne entre attaque locale et d√©fense adverse
    lam_home = (teamA_stats.get('avg_goals_scored', 1.5) + teamB_stats.get('avg_goals_conceded', 1.5)) / 2.0
    lam_away = (teamB_stats.get('avg_goals_scored', 1.5) + teamA_stats.get('avg_goals_conceded', 1.5)) / 2.0
    return lam_home * global_scale, lam_away * global_scale

def predict_combined(score_odds_map, teamA_stats=None, teamB_stats=None, diffExpected=2):
    """
    Algorithme combin√© utilisant Poisson + ImpliedOdds avec smoothing de voisinage.
    
    Args:
        score_odds_map: dict like {"2-4": 5.5, "3-1": 2.1, ...} ou list [{"score": "X-Y", "odds": Z}]
        teamA_stats: optional dict for lambdas calculation (see compute_team_lambdas)
        teamB_stats: optional dict for lambdas calculation (see compute_team_lambdas)
        diffExpected: valeur issue du learning_meta
        
    Returns:
        dict: {"mostProbableScore": str, "probabilities": dict, "confidence": float}
    """
    logger.info(f"üî¨ NOUVEL ALGORITHME COMBIN√â - diffExpected={diffExpected}, ALPHA={ALPHA}, BLEND_BETA={BLEND_BETA}")
    
    # Conversion si format liste
    if isinstance(score_odds_map, list):
        score_odds_map = {item["score"]: item["odds"] for item in score_odds_map}
    
    # 1) build implied probabilities from odds
    implied_raw = {}
    for s, o in score_odds_map.items():
        implied_raw[s] = implied_prob_from_odds(o)

    # 2) compute lambdas (Poisson) from team stats if provided, else neutral
    if teamA_stats and teamB_stats:
        lam_home, lam_away = compute_team_lambdas(teamA_stats, teamB_stats)
        logger.info(f"üìä Lambdas calcul√©s depuis stats √©quipes: Œª_home={lam_home:.2f}, Œª_away={lam_away:.2f}")
    else:
        lam_home, lam_away = 1.5, 1.5
        logger.info(f"üìä Lambdas par d√©faut: Œª_home={lam_home:.2f}, Œª_away={lam_away:.2f}")

    # 3) compute Poisson joint probs for all score pairs within clamp
    poisson_raw = {}
    for s in score_odds_map.keys():
        parts = s.replace(":", "-").split("-")
        if len(parts) != 2:
            continue
        try:
            h = int(parts[0]); a = int(parts[1])
        except ValueError:
            continue
            
        # clamp
        if h < 0 or a < 0 or h > MAX_GOALS or a > MAX_GOALS:
            # give tiny probability to extreme (or skip)
            poisson_raw[s] = EPS
            continue
        # joint prob = P(home goals = h) * P(away goals = a)
        p_h = poisson_pmf(h, lam_home)
        p_a = poisson_pmf(a, lam_away)
        poisson_raw[s] = max(EPS, p_h * p_a)

    # 4) apply diffExpected gaussian penalty/bonus to poisson_raw (make it stronger)
    adjusted_poisson = {}
    for s, p in poisson_raw.items():
        parts = s.split("-")
        try:
            h = int(parts[0]); a = int(parts[1])
        except ValueError:
            adjusted_poisson[s] = p
            continue
            
        diff = abs(a - h)
        # alpha is stronger than before to increase discrimination
        weight_diff = math.exp(-ALPHA * (diff - diffExpected)**2)
        adjusted_poisson[s] = p * weight_diff + EPS
        
        if p * weight_diff > 0.01:  # Log seulement les scores significatifs
            logger.debug(f"  {s}: Poisson={p:.4f}, diff={diff}, weight={weight_diff:.3f}, final={adjusted_poisson[s]:.4f}")

    # 5) normalize both distributions
    sum_pois = sum(adjusted_poisson.values()) or EPS
    pois_norm = {s: v / sum_pois for s, v in adjusted_poisson.items()}

    sum_impl = sum(implied_raw.values()) or EPS
    impl_norm = {s: implied_raw.get(s, 0.0) / sum_impl for s in adjusted_poisson.keys()}

    # 6) blend Poisson and ImpliedOdds with BLEND_BETA
    blended = {}
    for s in adjusted_poisson.keys():
        blended[s] = BLEND_BETA * pois_norm.get(s, 0.0) + (1 - BLEND_BETA) * impl_norm.get(s, 0.0) + EPS

    # 7) final normalization and convert to percentages
    total = sum(blended.values()) or EPS
    final_probs = {s: (v / total) * 100 for s, v in blended.items()}

    # 8) optional smoothing: boost nearby scores (small neighborhood smoothing)
    # (helps move mass from impossible isolated spikes)
    smoothed = defaultdict(float)
    for s, p in final_probs.items():
        try:
            h, a = map(int, s.split("-"))
        except ValueError:
            smoothed[s] = p
            continue
            
        # distribute 80% to self, 20% to neighbors (up/down by 1 goal)
        smoothed[s] += p * 0.80
        for dh, da in ((1,0),(-1,0),(0,1),(0,-1)):
            nh, na = h+dh, a+da
            key = f"{nh}-{na}"
            if 0 <= nh <= MAX_GOALS and 0 <= na <= MAX_GOALS:
                smoothed[key] += p * 0.05

    # normalize smoothed
    total_sm = sum(smoothed.values()) or EPS
    final_smoothed = {s: (v/total_sm) * 100 for s, v in smoothed.items() if s in final_probs}

    # pick top
    if not final_smoothed:
        return {"mostProbableScore": "Aucune donn√©e", "probabilities": {}, "confidence": 0.0}
    
    top_score = max(final_smoothed.items(), key=lambda x: x[1])[0]
    
    # Calculer la confiance
    confidence = calculate_confidence(final_smoothed, top_score)
    
    logger.info(f"üèÜ Score le plus probable (combin√©): {top_score} ({final_smoothed[top_score]:.2f}%)")
    logger.info(f"üíØ Confiance: {confidence:.2%}")
    
    return {
        "mostProbableScore": top_score,
        "probabilities": {k: round(v, 2) for k, v in final_smoothed.items()},
        "confidence": round(confidence, 3)
    }


# ============================================================================
# === FONCTION WRAPPER POUR COMPATIBILIT√â ===
# ============================================================================

def calculate_probabilities_v2(scores, diff_expected=2, use_combined=True, teamA_name=None, teamB_name=None):
    """
    Nouvelle interface unifi√©e pour le calcul de probabilit√©s.
    
    Args:
        scores: dict {score: odds} ou list [{"score": "X-Y", "odds": Z}]
        diff_expected: diff√©rence de buts attendue (d√©faut: 2)
        use_combined: Utiliser le nouvel algorithme combin√© (d√©faut: True)
        teamA_name: Nom √©quipe A (optionnel, pour stats)
        teamB_name: Nom √©quipe B (optionnel, pour stats)
    
    Returns:
        dict avec mostProbableScore, probabilities et confidence
    """
    if not scores:
        logger.warning("Aucune donn√©e pour la pr√©diction")
        return {"mostProbableScore": "Aucune donn√©e", "probabilities": {}, "confidence": 0.0}
    
    if use_combined:
        logger.info("üÜï Utilisation de l'algorithme COMBIN√â (Poisson + ImpliedOdds + Smoothing)")
        
        # R√©cup√©rer les stats des √©quipes si disponibles
        teamA_stats = None
        teamB_stats = None
        if teamA_name and teamB_name:
            gf_a, ga_a = get_team_stats(teamA_name)
            gf_b, ga_b = get_team_stats(teamB_name)
            teamA_stats = {'avg_goals_scored': gf_a, 'avg_goals_conceded': ga_a}
            teamB_stats = {'avg_goals_scored': gf_b, 'avg_goals_conceded': ga_b}
            logger.info(f"üìä Stats √©quipes charg√©es - {teamA_name}: {gf_a}G/{ga_a}C, {teamB_name}: {gf_b}G/{ga_b}C")
        
        return predict_combined(scores, teamA_stats, teamB_stats, diff_expected)
    else:
        logger.info("üìå Utilisation de l'algorithme CLASSIQUE (compatibilit√©)")
        return calculate_probabilities(scores, diff_expected)
