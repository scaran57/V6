import cv2
import pytesseract
import numpy as np
from PIL import Image
import re
import io
import logging
from debug_logger import log_debug, log_ocr_step

logger = logging.getLogger(__name__)

# Configuration Tesseract
pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'

# Langues disponibles (multilingue)
LANGS = "eng+fra+spa"

def preprocess_image(image_path: str) -> list:
    """
    Transforme une image en plusieurs variantes pr√©trait√©es pour maximiser la lecture OCR.
    Am√©lioration sp√©ciale: d√©tection texte BLANC sur VERT (boutons Unibet/Winamax)
    + CROP automatique du haut (interface/heure) pour √©viter faux positifs
    """
    # Charger l'image
    image = Image.open(image_path).convert("RGB")
    img = np.array(image)
    
    # NOUVEAU: Couper le haut de l'image (20% sup√©rieur = interface/heure/ic√¥nes)
    height, width = img.shape[:2]
    crop_top = int(height * 0.20)  # Enlever 20% du haut
    img_cropped = img[crop_top:, :]  # Garder de 20% √† 100%
    
    logger.info(f"‚úÇÔ∏è Image crop√©e: {height}px ‚Üí {img_cropped.shape[0]}px (enlev√© {crop_top}px du haut)")

    gray = cv2.cvtColor(img_cropped, cv2.COLOR_RGB2GRAY)
    blur = cv2.GaussianBlur(gray, (3, 3), 0)

    # D√©tection automatique du th√®me
    mean_brightness = np.mean(gray)
    is_dark_theme = mean_brightness < 100
    
    logger.info(f"üé® Th√®me d√©tect√©: {'SOMBRE' if is_dark_theme else 'CLAIR'} (luminosit√©: {mean_brightness:.1f})")

    versions = []

    # 1. Original (crop√©)
    versions.append(("original", gray))

    # 2. Invers√©e (utile pour th√®me sombre)
    versions.append(("inverted", cv2.bitwise_not(gray)))

    # 3. Adaptative Threshold (am√©liore distinction 0/O, 1/I)
    thr1 = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                 cv2.THRESH_BINARY, 11, 2)
    versions.append(("adaptive_thresh", thr1))

    # 4. CLAHE (am√©liore contraste)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl1 = clahe.apply(gray)
    versions.append(("clahe", cl1))

    # 5. Contraste + r√©duction bruit
    denoise = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)
    versions.append(("denoise", denoise))

    # 6. Combinaison blur + threshold (Otsu)
    _, thr2 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    versions.append(("otsu", thr2))
    
    # 7. Isolation du canal ROUGE (texte blanc sur vert appara√Æt bien)
    if len(img_cropped.shape) == 3:
        b, g, r = cv2.split(img_cropped)
        # Inverser le rouge pour que texte blanc devienne noir
        red_inverted = cv2.bitwise_not(r)
        versions.append(("red_channel_inv", red_inverted))
        
        # 8. Seuillage sur canal vert invers√©
        green_inv = cv2.bitwise_not(g)
        _, green_thresh = cv2.threshold(green_inv, 150, 255, cv2.THRESH_BINARY)
        versions.append(("green_thresh", green_thresh))
        
        # 9. Masque sp√©cifique pour boutons verts
        hsv = cv2.cvtColor(img_cropped, cv2.COLOR_RGB2HSV)
        lower_green = np.array([25, 40, 40])
        upper_green = np.array([95, 255, 255])
        mask = cv2.inRange(hsv, lower_green, upper_green)
        mask_inv = cv2.bitwise_not(mask)
        green_buttons = cv2.bitwise_and(gray, gray, mask=mask_inv)
        versions.append(("green_buttons", green_buttons))

    return versions


def clean_score(score_str: str) -> str:
    """
    Nettoie un score individuel en corrigeant les erreurs OCR courantes.
    """
    # Normalisation des caract√®res (erreurs fr√©quentes)
    score_str = score_str.replace("O", "0").replace("I", "1").replace("l", "1")
    score_str = score_str.replace(":", "-").replace("_", "-")
    
    # Extraire les chiffres
    parts = score_str.split('-')
    if len(parts) == 2:
        try:
            # Convertir en int puis back en string pour nettoyer
            a, b = int(parts[0]), int(parts[1])
            return f"{a}-{b}"
        except:
            pass
    return score_str


def extract_match_info(image_path: str):
    """
    Extrait le nom du match et le bookmaker depuis l'image.
    Version am√©lior√©e avec analyse compl√®te et d√©tection intelligente.
    """
    try:
        # Charger l'image compl√®te
        image = Image.open(image_path).convert("RGB")
        img = np.array(image)
        
        height, width = img.shape[:2]
        
        # Analyser TOUTE l'image avec plusieurs pr√©traitements
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        
        # Collecter le texte avec diff√©rentes m√©thodes OCR
        all_texts = []
        
        # M√©thode 1: OCR normal
        text1 = pytesseract.image_to_string(Image.fromarray(gray), lang=LANGS, config="--psm 6")
        all_texts.append(text1)
        
        # M√©thode 2: OCR invers√© (pour th√®mes sombres)
        inverted = cv2.bitwise_not(gray)
        text2 = pytesseract.image_to_string(Image.fromarray(inverted), lang=LANGS, config="--psm 6")
        all_texts.append(text2)
        
        # M√©thode 3: OCR avec seuillage adaptatif
        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
        text3 = pytesseract.image_to_string(Image.fromarray(thresh), lang=LANGS, config="--psm 6")
        all_texts.append(text3)
        
        # M√©thode 4: Section haute uniquement (meilleure pour titres)
        top_section = img[:int(height * 0.35), :]
        gray_top = cv2.cvtColor(top_section, cv2.COLOR_RGB2GRAY)
        text4 = pytesseract.image_to_string(Image.fromarray(gray_top), lang=LANGS, config="--psm 6")
        all_texts.append(text4)
        
        # Combiner tous les textes
        all_text = "\n".join(all_texts)
        
        logger.info(f"üìù Texte OCR extrait ({len(all_text)} caract√®res)")
        logger.info(f"√âchantillon: {all_text[:400]}")
        
        # ========== D√âTECTION DU BOOKMAKER ==========
        bookmaker = None
        bookmaker_keywords = {
            "unibet": "Unibet",
            "betclic": "BetClic", 
            "betclick": "BetClic",
            "winamax": "Winamax",
            "wina max": "Winamax",
            "pmu": "PMU",
            "parions": "Parions Sport",
            "bwin": "Bwin",
            "zebet": "ZEbet",
            "netbet": "NetBet",
            "france pari": "France Pari",
            "bet365": "Bet365",
            "1xbet": "1xBet",
            "fdj": "Parions Sport"
        }
        
        text_lower = all_text.lower()
        for keyword, name in bookmaker_keywords.items():
            if keyword in text_lower:
                bookmaker = name
                logger.info(f"‚úì Bookmaker: {keyword} ‚Üí {name}")
                break
        
        # Fallback: nom de fichier
        if not bookmaker:
            filename_lower = image_path.lower()
            for keyword, name in bookmaker_keywords.items():
                if keyword in filename_lower:
                    bookmaker = name
                    logger.info(f"‚úì Bookmaker (fichier): {name}")
                    break
        
        # ========== D√âTECTION DU NOM DU MATCH ==========
        match_name = None
        
        # Extraire toutes les lignes du texte
        lines = all_text.split('\n')
        lines = [line.strip() for line in lines if line.strip()]
        
        # Chercher les noms d'√©quipes (mots capitalis√©s de 3+ caract√®res)
        team_candidates = []
        for line in lines:
            # Ignorer les lignes avec beaucoup de chiffres ou de symboles
            if len(re.findall(r'\d', line)) > len(line) * 0.3:
                continue
            if len(line) < 3 or len(line) > 40:
                continue
            
            # Chercher des mots qui commencent par une majuscule
            words = line.split()
            team_name_parts = []
            for word in words:
                # Mot commence par majuscule, pas de chiffres, 3+ caract√®res
                if word and word[0].isupper() and not any(c.isdigit() for c in word) and len(word) >= 3:
                    # Exclure les mots communs
                    if word.lower() not in ['score', 'exact', 'cote', 'match', 'autre', 'but', 'foot', 'football']:
                        team_name_parts.append(word)
            
            if team_name_parts:
                potential_team = ' '.join(team_name_parts[:3])  # Max 3 mots
                if len(potential_team) >= 4:
                    team_candidates.append(potential_team)
        
        # Filtrer et d√©dupliquer
        team_candidates = list(dict.fromkeys(team_candidates))  # Garder l'ordre, supprimer doublons
        
        logger.info(f"üîç √âquipes candidates: {team_candidates[:10]}")
        
        # Chercher des paires d'√©quipes
        if len(team_candidates) >= 2:
            # Prendre les 2 premi√®res √©quipes diff√©rentes
            team1 = team_candidates[0]
            team2 = None
            
            for candidate in team_candidates[1:]:
                # V√©rifier que ce n'est pas une variation du m√™me nom
                if candidate.lower() != team1.lower() and not (candidate in team1 or team1 in candidate):
                    team2 = candidate
                    break
            
            if team2:
                match_name = f"{team1} vs {team2}"
                logger.info(f"‚úì Match d√©tect√©: {match_name}")
        
        # Pattern alternatif: chercher "vs", "v", "-" dans le texte
        if not match_name:
            vs_patterns = [
                r"([A-Z√Ä-≈∏][a-zA-Z√Ä-√ø\s]{2,20})\s+(?:vs\.?|v\.?|-|‚Äî)\s+([A-Z√Ä-≈∏][a-zA-Z√Ä-√ø\s]{2,20})",
            ]
            
            for pattern in vs_patterns:
                matches = re.finditer(pattern, all_text, re.MULTILINE | re.IGNORECASE)
                for match in matches:
                    team1 = match.group(1).strip()
                    team2 = match.group(2).strip()
                    
                    # Validation
                    if len(team1) >= 3 and len(team2) >= 3:
                        if not any(c.isdigit() for c in team1+team2):
                            match_name = f"{team1} vs {team2}"
                            logger.info(f"‚úì Match (pattern vs): {match_name}")
                            break
                
                if match_name:
                    break
        
        logger.info(f"üèüÔ∏è R√©sultat final - Match: {match_name or 'Match non d√©tect√©'}")
        logger.info(f"üé∞ R√©sultat final - Bookmaker: {bookmaker or 'Bookmaker inconnu'}")
        
        return {
            "match_name": match_name or "Match non d√©tect√©",
            "bookmaker": bookmaker or "Bookmaker inconnu"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur extraction: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            "match_name": "Match non d√©tect√©",
            "bookmaker": "Bookmaker inconnu"
        }


def extract_odds(image_path: str):
    """
    Extrait les cotes et scores depuis une image de bookmaker.
    Version am√©lior√©e avec meilleure stabilit√© OCR et distinction 0/O, 1/I.
    Compatible avec l'API existante.
    """
    try:
        logger.info("üîç D√©but de l'extraction OCR am√©lior√©e...")
        
        # Obtenir toutes les versions preprocessed
        versions = preprocess_image(image_path)
        
        all_texts = []
        
        # OCR sur chaque version
        for img_name, cv_img in versions:
            logger.info(f"üì∏ OCR sur version: {img_name}")
            try:
                # Convertir numpy array en PIL Image
                pil_img = Image.fromarray(cv_img)
                
                # Utiliser PSM 11 (sparse text) pour boutons isol√©s si c'est une version sp√©ciale
                if img_name in ["red_channel_inv", "green_thresh", "green_buttons"]:
                    text = pytesseract.image_to_string(pil_img, lang=LANGS, config="--psm 11")
                else:
                    text = pytesseract.image_to_string(pil_img, lang=LANGS, config="--psm 6")
                
                if text.strip():
                    all_texts.append((img_name, text))
                    logger.info(f"‚úÖ {img_name}: {len(text)} caract√®res extraits")
            except Exception as e:
                logger.warning(f"Erreur OCR {img_name}: {e}")
        
        logger.info(f"‚úÖ {len(all_texts)} textes extraits au total")
        
        # DEBUG: Log √©tape OCR
        log_ocr_step("Extraction OCR compl√©t√©e", len(all_texts))
        
        # Afficher un √©chantillon du meilleur texte
        if all_texts:
            longest_text = max(all_texts, key=lambda x: len(x[1]))
            logger.info(f"=== MEILLEUR TEXTE OCR ({longest_text[0]}) ===\n{longest_text[1][:300]}\n=== FIN ===")
        
        # Extraire les scores et cotes
        scores = []
        seen_scores = set()
        
        for source_name, text in all_texts:
            # Normalisation du texte
            text_normalized = text.replace("O", "0").replace("I", "1").replace("l", "1")
            text_normalized = text_normalized.replace(",", ".")
            
            # Pattern 1: Score suivi de cote - ex: "1-0 15.20"
            pattern1 = re.compile(r"(\d+[-:]\d+)\s*([0-9]+\.[0-9]+)")
            for match in pattern1.finditer(text_normalized):
                score = clean_score(match.group(1))
                
                if re.match(r'^\d{1,2}-\d{1,2}$', score):  # Format valide
                    odds_str = match.group(2)
                    try:
                        odds = float(odds_str)
                        if odds > 100:  # Probablement un pourcentage
                            continue
                        if 1.01 <= odds <= 100:
                            score_key = f"{score}_{odds}"
                            if score_key not in seen_scores:
                                scores.append({"score": score, "odds": odds})
                                seen_scores.add(score_key)
                                logger.info(f"‚úì [{source_name}] Pattern1 - {score} @ {odds}")
                    except ValueError:
                        continue
            
            # Pattern 2: Extraire tous les scores, puis toutes les cotes
            all_scores_in_text = []
            all_odds_in_text = []
            
            # Scores
            score_matches = re.findall(r"(\d+[-:]\d+)", text_normalized)
            for s in score_matches:
                score = clean_score(s)
                if re.match(r'^\d{1,2}-\d{1,2}$', score):
                    all_scores_in_text.append(score)
            
            # Cotes (nombres d√©cimaux entre 1.01 et 100)
            odds_matches = re.findall(r"([0-9]+\.[0-9]+)", text_normalized)
            for o in odds_matches:
                try:
                    odds_val = float(o)
                    if 1.01 <= odds_val <= 100:
                        all_odds_in_text.append(odds_val)
                except:
                    continue
            
            # NOUVEAU: Aussi chercher nombres ENTIERS comme cotes (ex: "13", "24")
            # Format Unibet avec gros chiffres
            integer_odds = re.findall(r"\b([1-9][0-9]?)\b", text_normalized)
            for o in integer_odds:
                try:
                    odds_val = float(o)
                    if 2 <= odds_val <= 100:  # Cotes enti√®res raisonnables
                        all_odds_in_text.append(odds_val)
                except:
                    continue
            
            logger.info(f"[{source_name}] Scores: {len(all_scores_in_text)}, Cotes: {len(all_odds_in_text)}")
            
            # Associer dans l'ordre
            min_len = min(len(all_scores_in_text), len(all_odds_in_text))
            for i in range(min_len):
                score = all_scores_in_text[i]
                odds = all_odds_in_text[i]
                score_key = f"{score}_{odds}"
                if score_key not in seen_scores:
                    scores.append({"score": score, "odds": odds})
                    seen_scores.add(score_key)
                    logger.info(f"‚úì [{source_name}] Pattern2 - {score} @ {odds}")
        
        # Chercher "Autre"
        combined_text = " ".join([t[1] for t in all_texts])
        for keyword in ["autre", "other", "any"]:
            other_match = re.search(rf"{keyword}\s*([0-9]+\.[0-9]+)", combined_text, re.IGNORECASE)
            if other_match:
                try:
                    odds = float(other_match.group(1))
                    if not any(s["score"] == "Autre" for s in scores):
                        scores.append({"score": "Autre", "odds": odds})
                        logger.info(f"‚úì Option 'Autre' @ {odds}")
                        break
                except:
                    pass
        
        # D√©dupliquer et valider
        final_scores = []
        score_odds_map = {}
        
        for item in scores:
            score = item["score"]
            odds = item["odds"]
            
            # Validation des scores
            if score != "Autre":
                parts = score.split('-')
                if len(parts) == 2:
                    try:
                        home, away = int(parts[0]), int(parts[1])
                        
                        # Rejeter les scores impossibles
                        if home < 0 or away < 0:
                            logger.warning(f"‚ö†Ô∏è Score rejet√© (n√©gatif): {score}")
                            continue
                        if home > 9 or away > 9:
                            logger.warning(f"‚ö†Ô∏è Score rejet√© (>9 buts): {score}")
                            continue
                        if abs(home - away) > 4:
                            logger.warning(f"‚ö†Ô∏è Score rejet√© (diff√©rence >4): {score}")
                            continue
                    except:
                        logger.warning(f"‚ö†Ô∏è Score rejet√© (format invalide): {score}")
                        continue
            
            if score not in score_odds_map:
                score_odds_map[score] = []
            score_odds_map[score].append(odds)
        
        # Prendre la cote m√©diane pour chaque score
        for score, odds_list in score_odds_map.items():
            odds_list.sort()
            median_odds = odds_list[len(odds_list) // 2]
            final_scores.append({"score": score, "odds": median_odds})
        
        logger.info(f"üìä TOTAL FINAL: {len(final_scores)} scores uniques extraits")
        
        # DEBUG: Log scores finaux extraits
        log_ocr_step("Scores valid√©s et filtr√©s", len(final_scores), final_scores)
        
        return final_scores
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'extraction OCR: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return []