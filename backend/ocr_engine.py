import cv2
import pytesseract
import numpy as np
from PIL import Image
import re
import io
import logging
from debug_logger import log_debug, log_ocr_step

logger = logging.getLogger(__name__)

# Configuration Tesseract
pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'

# Langues disponibles (multilingue)
LANGS = "eng+fra+spa"

# === NOUVEAU: Pr√©processeur OCR avanc√© ===
USE_ADVANCED_PREPROCESSOR = False  # D√âSACTIV√â : Cr√©e des artefacts qui trompent l'OCR (lit 100 comme 2.0)

try:
    from tools.ocr_preprocessor import preprocess_for_ocr as advanced_preprocess
    logger.info("‚ö†Ô∏è Pr√©processeur OCR avanc√© D√âSACTIV√â (cause erreurs de lecture)")
except ImportError:
    logger.warning("‚ö†Ô∏è Pr√©processeur OCR avanc√© non disponible")
    USE_ADVANCED_PREPROCESSOR = False

def preprocess_image(image_path: str, use_advanced: bool = None) -> list:
    """
    Transforme une image en plusieurs variantes pr√©trait√©es pour maximiser la lecture OCR.
    Am√©lioration sp√©ciale: d√©tection texte BLANC sur VERT (boutons Unibet/Winamax)
    + CROP automatique du haut (interface/heure) pour √©viter faux positifs
    
    Args:
        image_path: Chemin de l'image
        use_advanced: Force l'utilisation du pr√©processeur avanc√© (None = auto)
    
    Returns:
        Liste de tuples (nom_variante, image_pr√©trait√©e)
    """
    # D√©cider si on utilise le pr√©processeur avanc√©
    use_adv = use_advanced if use_advanced is not None else USE_ADVANCED_PREPROCESSOR
    
    # Si pr√©processeur avanc√© activ√©, l'utiliser EN PLUS des variantes classiques
    if use_adv:
        try:
            logger.info("üîß Utilisation du pr√©processeur OCR avanc√©")
            advanced_img = advanced_preprocess(
                image_path,
                remove_overlay=True,
                auto_crop=True,
                enhance=True,
                denoise=False
            )
            # Ajouter cette version en premi√®re position
            advanced_versions = [("advanced_full", advanced_img)]
            logger.info("‚úÖ Pr√©traitement avanc√© r√©ussi")
        except Exception as e:
            logger.error(f"‚ö†Ô∏è Erreur pr√©processeur avanc√©: {e}")
            advanced_versions = []
    else:
        advanced_versions = []
    
    # Charger l'image
    image = Image.open(image_path).convert("RGB")
    img = np.array(image)
    
    # NOUVEAU: Couper le haut de l'image (20% sup√©rieur = interface/heure/ic√¥nes)
    height, width = img.shape[:2]
    crop_top = int(height * 0.20)  # Enlever 20% du haut
    img_cropped = img[crop_top:, :]  # Garder de 20% √† 100%
    
    logger.info(f"‚úÇÔ∏è Image crop√©e: {height}px ‚Üí {img_cropped.shape[0]}px (enlev√© {crop_top}px du haut)")

    gray = cv2.cvtColor(img_cropped, cv2.COLOR_RGB2GRAY)
    blur = cv2.GaussianBlur(gray, (3, 3), 0)

    # D√©tection automatique du th√®me
    mean_brightness = np.mean(gray)
    is_dark_theme = mean_brightness < 100
    
    logger.info(f"üé® Th√®me d√©tect√©: {'SOMBRE' if is_dark_theme else 'CLAIR'} (luminosit√©: {mean_brightness:.1f})")

    versions = []

    # 1. Original (crop√©)
    versions.append(("original", gray))

    # 2. Invers√©e (utile pour th√®me sombre)
    versions.append(("inverted", cv2.bitwise_not(gray)))

    # 3. Adaptative Threshold (am√©liore distinction 0/O, 1/I)
    thr1 = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                 cv2.THRESH_BINARY, 11, 2)
    versions.append(("adaptive_thresh", thr1))

    # 4. CLAHE (am√©liore contraste)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl1 = clahe.apply(gray)
    versions.append(("clahe", cl1))

    # 5. Contraste + r√©duction bruit
    denoise = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)
    versions.append(("denoise", denoise))

    # 6. Combinaison blur + threshold (Otsu)
    _, thr2 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    versions.append(("otsu", thr2))
    
    # 7. Isolation du canal ROUGE (texte blanc sur vert appara√Æt bien)
    if len(img_cropped.shape) == 3:
        b, g, r = cv2.split(img_cropped)
        # Inverser le rouge pour que texte blanc devienne noir
        red_inverted = cv2.bitwise_not(r)
        versions.append(("red_channel_inv", red_inverted))
        
        # 8. Seuillage sur canal vert invers√©
        green_inv = cv2.bitwise_not(g)
        _, green_thresh = cv2.threshold(green_inv, 150, 255, cv2.THRESH_BINARY)
        versions.append(("green_thresh", green_thresh))
        
        # 9. Masque sp√©cifique pour boutons verts
        hsv = cv2.cvtColor(img_cropped, cv2.COLOR_RGB2HSV)
        lower_green = np.array([25, 40, 40])
        upper_green = np.array([95, 255, 255])
        mask = cv2.inRange(hsv, lower_green, upper_green)
        mask_inv = cv2.bitwise_not(mask)
        green_buttons = cv2.bitwise_and(gray, gray, mask=mask_inv)
        versions.append(("green_buttons", green_buttons))

    # Ajouter les versions avanc√©es en premier (priorit√©)
    return advanced_versions + versions


def clean_score(score_str: str) -> str:
    """
    Nettoie un score individuel en corrigeant les erreurs OCR courantes.
    """
    # Normalisation des caract√®res (erreurs fr√©quentes)
    score_str = score_str.replace("O", "0").replace("I", "1").replace("l", "1")
    score_str = score_str.replace(":", "-").replace("_", "-")
    
    # Extraire les chiffres
    parts = score_str.split('-')
    if len(parts) == 2:
        try:
            # Convertir en int puis back en string pour nettoyer
            a, b = int(parts[0]), int(parts[1])
            return f"{a}-{b}"
        except:
            pass
    return score_str


def extract_bold_team_names_parionssport(image_path: str):
    """
    Extraction sp√©cialis√©e pour Parions Sport:
    - Cible les GRANDES LETTRES en GRAS
    - Zone pr√®s des drapeaux (section haute de l'image)
    - Am√©lioration du contraste pour texte en gras
    """
    try:
        image = Image.open(image_path).convert("RGB")
        img = np.array(image)
        height, width = img.shape[:2]
        
        # Zone haute o√π se trouvent g√©n√©ralement les noms d'√©quipes (5-40% de la hauteur)
        # √âlargi pour capturer plus de variantes de mise en page
        team_zone = img[int(height * 0.05):int(height * 0.40), :]
        
        # Convertir en niveaux de gris
        gray = cv2.cvtColor(team_zone, cv2.COLOR_RGB2GRAY)
        
        # Am√©liorer le contraste pour d√©tecter le texte en GRAS
        # Les caract√®res gras ont plus de pixels noirs/fonc√©s
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        
        # Seuillage pour isoler le texte fonc√© (gras)
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # Dilatation pour renforcer les caract√®res gras
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        dilated = cv2.dilate(binary, kernel, iterations=1)
        
        # OCR avec configuration pour texte large et espac√© (noms d'√©quipes)
        # Utiliser PSM 6 (bloc de texte uniforme) et accepter lettres + espaces
        custom_config = r'--oem 3 --psm 6'
        
        text = pytesseract.image_to_string(
            Image.fromarray(dilated),
            lang=LANGS,
            config=custom_config
        )
        
        logger.info(f"üéØ OCR sp√©cialis√© Parions Sport (texte gras): {text[:300]}")
        
        # Nettoyer et extraire les noms d'√©quipes
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        
        # Mots √† exclure (UI elements, bookmaker text, etc.)
        excluded_words_lower = {
            'league', 'ligue', 'champions', 'europa', 'conference', 'coupe', 'cup',
            'qualification', 'barrage', 'finale', 'demi', 'quart', 'huiti√®me',
            'match', 'jour', 'journ√©e', 'tour', 'phase', 'groupe', 'poule',
            'parions', 'sport', 'fdj', 'pmu', 'cote', 'cotes', 'score', 'exact',
            'stats', 'statistiques', 'live', 'direct', 'r√©sultat', 'but', 'buts',
            'the', 'and', 'vs', 'versus'
        }
        
        # Filtrer les lignes qui ressemblent √† des noms d'√©quipes
        team_candidates = []
        raw_lines_log = []
        
        for line in lines:
            raw_lines_log.append(line[:50])  # Pour debugging
            
            # Ignorer lignes trop courtes ou trop longues
            if len(line) < 2 or len(line) > 60:
                continue
            
            # Ignorer si trop de chiffres (probablement des cotes)
            digit_count = sum(1 for c in line if c.isdigit())
            if digit_count > len(line) * 0.3:
                continue
            
            # Ignorer si contient des symboles de cotes suspects (:, x, /, \)
            # Mais ACCEPTER les tirets (-) et points (.) car pr√©sents dans noms d'√©quipes
            suspect_symbol_count = sum(1 for c in line if c in ':x/\\')
            if suspect_symbol_count > 1:
                continue
            
            # Nettoyer la ligne
            clean_line = line.strip()
            
            # V√©rifier si la ligne contient des mots exclus
            line_lower = clean_line.lower()
            words_in_line = line_lower.split()
            
            # Exclure si un mot complet est dans excluded_words_lower
            has_excluded = False
            for word in words_in_line:
                if word in excluded_words_lower:
                    has_excluded = True
                    break
            
            if has_excluded:
                continue
            
            # Garder si commence par une majuscule et contient principalement des lettres ou espaces
            alpha_space_count = sum(1 for c in clean_line if c.isalpha() or c.isspace())
            total_relevant = sum(1 for c in clean_line if c.isalpha() or c.isspace() or c in '-.')
            
            if (alpha_space_count > len(clean_line) * 0.6 and 
                clean_line[0].isupper() and
                total_relevant > len(clean_line) * 0.8):
                team_candidates.append(clean_line)
        
        logger.info(f"üìÑ Lignes brutes extraites: {raw_lines_log[:10]}")
        
        if team_candidates:
            logger.info(f"‚úÖ Candidats trouv√©s ({len(team_candidates)}): {team_candidates}")
        else:
            logger.warning(f"‚ö†Ô∏è Aucun candidat trouv√©. Texte brut extrait: {text[:500]}")
        
        return team_candidates
        
    except Exception as e:
        logger.error(f"Erreur extraction sp√©cialis√©e: {e}")
        return []


def extract_match_info(image_path: str):
    """
    Extrait le nom du match et le bookmaker depuis l'image.
    Version am√©lior√©e avec analyse compl√®te et d√©tection intelligente.
    PRIORIT√â: Extraction sp√©cialis√©e pour Parions Sport (texte en gras)
    """
    try:
        # Charger l'image compl√®te
        image = Image.open(image_path).convert("RGB")
        img = np.array(image)
        
        height, width = img.shape[:2]
        
        # Analyser TOUTE l'image avec plusieurs pr√©traitements
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        
        # Collecter le texte avec diff√©rentes m√©thodes OCR
        all_texts = []
        
        # M√©thode 1: OCR normal
        text1 = pytesseract.image_to_string(Image.fromarray(gray), lang=LANGS, config="--psm 6")
        all_texts.append(text1)
        
        # M√©thode 2: OCR invers√© (pour th√®mes sombres)
        inverted = cv2.bitwise_not(gray)
        text2 = pytesseract.image_to_string(Image.fromarray(inverted), lang=LANGS, config="--psm 6")
        all_texts.append(text2)
        
        # M√©thode 3: OCR avec seuillage adaptatif
        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
        text3 = pytesseract.image_to_string(Image.fromarray(thresh), lang=LANGS, config="--psm 6")
        all_texts.append(text3)
        
        # M√©thode 4: Section centrale (15-45% de la hauteur) - √©vite header/footer
        # C'est ici que se trouvent g√©n√©ralement les noms d'√©quipes
        central_section = img[int(height * 0.15):int(height * 0.45), :]
        gray_central = cv2.cvtColor(central_section, cv2.COLOR_RGB2GRAY)
        text4 = pytesseract.image_to_string(Image.fromarray(gray_central), lang=LANGS, config="--psm 6")
        all_texts.append(text4)
        
        # M√©thode 5: Section haute (meilleure pour titres si pr√©sents)
        top_section = img[:int(height * 0.25), :]
        gray_top = cv2.cvtColor(top_section, cv2.COLOR_RGB2GRAY)
        text5 = pytesseract.image_to_string(Image.fromarray(gray_top), lang=LANGS, config="--psm 6")
        all_texts.append(text5)
        
        # Combiner tous les textes
        all_text = "\n".join(all_texts)
        
        logger.info(f"üìù Texte OCR extrait ({len(all_text)} caract√®res)")
        logger.info(f"√âchantillon: {all_text[:400]}")
        
        # ========== D√âTECTION DU BOOKMAKER ==========
        bookmaker = None
        bookmaker_keywords = {
            "unibet": "Unibet",
            "betclic": "BetClic", 
            "betclick": "BetClic",
            "winamax": "Winamax",
            "wina max": "Winamax",
            "pmu": "PMU",
            "parions": "Parions Sport",
            "bwin": "Bwin",
            "zebet": "ZEbet",
            "netbet": "NetBet",
            "france pari": "France Pari",
            "bet365": "Bet365",
            "1xbet": "1xBet",
            "fdj": "Parions Sport"
        }
        
        text_lower = all_text.lower()
        for keyword, name in bookmaker_keywords.items():
            if keyword in text_lower:
                bookmaker = name
                logger.info(f"‚úì Bookmaker: {keyword} ‚Üí {name}")
                break
        
        # Fallback: nom de fichier
        if not bookmaker:
            filename_lower = image_path.lower()
            for keyword, name in bookmaker_keywords.items():
                if keyword in filename_lower:
                    bookmaker = name
                    logger.info(f"‚úì Bookmaker (fichier): {name}")
                    break
        
        # ========== D√âTECTION DU NOM DU MATCH ==========
        match_name = None
        
        # SI PARIONS SPORT D√âTECT√â : Utiliser l'extraction sp√©cialis√©e pour texte en GRAS
        if bookmaker and "Parions" in bookmaker:
            logger.info("üéØ Bookmaker Parions Sport d√©tect√© - Utilisation extraction sp√©cialis√©e (texte gras)")
            bold_teams = extract_bold_team_names_parionssport(image_path)
            
            # V√©rifier si un candidat contient d√©j√† les deux √©quipes s√©par√©es par "-"
            for candidate in bold_teams:
                if " - " in candidate or " -" in candidate or "- " in candidate:
                    # Splitter sur le tiret
                    parts = re.split(r'\s*-\s*', candidate)
                    if len(parts) == 2:
                        team1 = parts[0].strip()
                        team2 = parts[1].strip()
                        if len(team1) >= 2 and len(team2) >= 2:
                            match_name = f"{team1} - {team2}"
                            logger.info(f"‚úÖ Match d√©tect√© (ligne compl√®te avec tiret): {match_name}")
                            return {"match_name": match_name, "bookmaker": bookmaker}
            
            if len(bold_teams) >= 2:
                # Prendre les 2 premiers candidats comme √©quipes
                match_name = f"{bold_teams[0]} - {bold_teams[1]}"
                logger.info(f"‚úÖ Match d√©tect√© (m√©thode gras - 2 lignes): {match_name}")
                return {"match_name": match_name, "bookmaker": bookmaker}
            elif len(bold_teams) == 1:
                # Un seul nom d√©tect√©, chercher le second dans le texte g√©n√©ral
                match_name = f"{bold_teams[0]} - ?"
                logger.info(f"‚ö†Ô∏è Un seul nom d√©tect√© (m√©thode gras): {bold_teams[0]}")
        
        # Extraire toutes les lignes du texte (m√©thode classique si Parions Sport √©choue ou autre bookmaker)
        lines = all_text.split('\n')
        lines = [line.strip() for line in lines if line.strip()]
        
        # Mots/phrases √† exclure (interface, boutons, contexte, bookmakers)
        excluded_words = {
            'score', 'exact', 'cote', 'match', 'autre', 'but', 'foot', 'football',
            'preview', 'bookmaker', 'top', 'voir', 'cotes', 'extraites', 'scores',
            'inscrire', 'connexion', 'parier', 'paris', 'live', 'direct', 'resultat',
            'probabilite', 'recommandation', 'interpretation', 'confiance', 'analyse',
            'analyser', 'predire', 'upload', 'image', 'choisir', 'glissez', 'cliquez',
            'temps', 'ecart', 'handicap', 'corner', 'carton', 'penalty', 'buteur',
            'ligue', 'champions', 'europa', 'coupe', 'division', 'finale', 'groupe',
            'journee', 'tour', 'phase', 'qualification', 'premier', 'deuxieme',
            'coro', 'produit', 'made', 'with', 'emergent', 'plus', 'probable',
            'aptos', 'application', 'android', 'ios', 'mobile', 'championsleague',
            'unibet', 'betclic', 'winamax', 'parions', 'sport', 'fdj', 'pmu',
            'stats', 'compos', 'mesure', 'parisurmesure', 'compositions', 'statistiques'
        }
        
        # Phrases √† exclure (multi-mots)
        excluded_phrases = {
            'mi-temps', 'mi temps', 'score exact', 'the coro', 'coro produit',
            'top scores', 'top 3', 'niveau de', 'made with', 'pari sur mesure',
            'sur mesure'
        }
        
        # Chercher les noms d'√©quipes (mots capitalis√©s de 3+ caract√®res)
        team_candidates = []
        for line in lines:
            # Ignorer les lignes avec beaucoup de chiffres ou de symboles
            if len(re.findall(r'\d', line)) > len(line) * 0.3:
                continue
            if len(line) < 3 or len(line) > 40:
                continue
            
            # Chercher des mots qui commencent par une majuscule
            words = line.split()
            team_name_parts = []
            for word in words:
                # Nettoyer le mot (enlever ponctuation)
                clean_word = re.sub(r'[^\w\s\-\'√Ä-√ø]', '', word)
                
                # Mot commence par majuscule, pas de chiffres, 3+ caract√®res
                if clean_word and clean_word[0].isupper() and not any(c.isdigit() for c in clean_word) and len(clean_word) >= 3:
                    # Exclure les mots communs d'interface
                    if clean_word.lower() not in excluded_words:
                        team_name_parts.append(clean_word)
            
            if team_name_parts:
                potential_team = ' '.join(team_name_parts[:3])  # Max 3 mots
                
                # V√©rifier que ce n'est pas une phrase exclue
                is_excluded = False
                for excluded_phrase in excluded_phrases:
                    if excluded_phrase in potential_team.lower():
                        is_excluded = True
                        break
                
                if not is_excluded and len(potential_team) >= 4:
                    team_candidates.append(potential_team)
        
        # Filtrer et d√©dupliquer
        team_candidates = list(dict.fromkeys(team_candidates))  # Garder l'ordre, supprimer doublons
        
        logger.info(f"üîç √âquipes candidates: {team_candidates[:10]}")
        
        # Chercher des paires d'√©quipes
        if len(team_candidates) >= 2:
            # Prendre les 2 premi√®res √©quipes diff√©rentes et valides
            team1 = None
            team2 = None
            
            # Trouver la premi√®re √©quipe valide
            for candidate in team_candidates:
                # Une vraie √©quipe a g√©n√©ralement au moins 4 caract√®res
                # et ne contient pas trop de mots (max 3)
                word_count = len(candidate.split())
                if len(candidate) >= 4 and word_count <= 3:
                    team1 = candidate
                    break
            
            if team1:
                # Chercher la deuxi√®me √©quipe (diff√©rente)
                for candidate in team_candidates:
                    if candidate == team1:
                        continue
                    
                    # V√©rifier que ce n'est pas une variation du m√™me nom
                    similarity_check = (
                        candidate.lower() != team1.lower() and 
                        not (candidate.lower() in team1.lower()) and 
                        not (team1.lower() in candidate.lower())
                    )
                    
                    word_count = len(candidate.split())
                    if similarity_check and len(candidate) >= 4 and word_count <= 3:
                        team2 = candidate
                        break
            
            if team1 and team2:
                # Nettoyer les noms d'√©quipes (enlever les mots coll√©s type "ChampionsLeague")
                team1_clean = ' '.join([w for w in team1.split() if w.lower() not in excluded_words and len(w) >= 3])
                team2_clean = ' '.join([w for w in team2.split() if w.lower() not in excluded_words and len(w) >= 3])
                
                if team1_clean and team2_clean:
                    match_name = f"{team1_clean} - {team2_clean}"  # Utiliser tiret au lieu de "vs"
                    logger.info(f"‚úì Match d√©tect√©: {match_name}")
        
        # Pattern alternatif: chercher "vs", "v", "-" dans le texte
        if not match_name:
            vs_patterns = [
                r"([A-Z√Ä-≈∏][a-zA-Z√Ä-√ø\s]{2,20})\s+(?:vs\.?|v\.?|-|‚Äî)\s+([A-Z√Ä-≈∏][a-zA-Z√Ä-√ø\s]{2,20})",
            ]
            
            for pattern in vs_patterns:
                matches = re.finditer(pattern, all_text, re.MULTILINE | re.IGNORECASE)
                for match in matches:
                    team1 = match.group(1).strip()
                    team2 = match.group(2).strip()
                    
                    # Validation et nettoyage
                    if len(team1) >= 3 and len(team2) >= 3:
                        if not any(c.isdigit() for c in team1+team2):
                            # Nettoyer les noms
                            team1_clean = ' '.join([w for w in team1.split() if w.lower() not in excluded_words and len(w) >= 3])
                            team2_clean = ' '.join([w for w in team2.split() if w.lower() not in excluded_words and len(w) >= 3])
                            
                            if team1_clean and team2_clean:
                                match_name = f"{team1_clean} - {team2_clean}"  # Tiret au lieu de "vs"
                                logger.info(f"‚úì Match (pattern): {match_name}")
                                break
                
                if match_name:
                    break
        
        logger.info(f"üèüÔ∏è R√©sultat final - Match: {match_name or 'Match non d√©tect√©'}")
        logger.info(f"üé∞ R√©sultat final - Bookmaker: {bookmaker or 'Bookmaker inconnu'}")
        
        return {
            "match_name": match_name or "Match non d√©tect√©",
            "bookmaker": bookmaker or "Bookmaker inconnu"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur extraction: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            "match_name": "Match non d√©tect√©",
            "bookmaker": "Bookmaker inconnu"
        }


def extract_odds_with_vision(image_path: str):
    """
    Extrait les cotes via Vision GPT-4 OCR (plus pr√©cis que Tesseract)
    """
    try:
        from tools.vision_ocr import extract_odds_from_image
        logger.info("üîÆ Utilisation de Vision GPT-4 OCR pour extraction des cotes...")
        result = extract_odds_from_image(image_path)
        
        # Si Vision OCR retourne un dict structur√©, le convertir au format attendu
        if isinstance(result, dict) and 'raw_text' in result:
            # Vision OCR a √©chou√©, fallback Tesseract
            logger.warning("‚ö†Ô∏è Vision OCR a √©chou√©, fallback vers Tesseract")
            return extract_odds_tesseract(image_path)
        
        return result
    except Exception as e:
        logger.error(f"‚ùå Erreur Vision OCR: {e}")
        logger.info("‚Ü©Ô∏è Fallback vers Tesseract")
        return extract_odds_tesseract(image_path)

def extract_odds(image_path: str, use_vision: bool = False):
    """
    Extrait les cotes et scores depuis une image de bookmaker.
    
    Args:
        image_path: Chemin de l'image
        use_vision: Si True, utilise Vision GPT-4 (plus pr√©cis, mais co√ªte des tokens)
    
    Returns:
        Liste de dicts {"score": "X-Y", "odds": float}
    """
    if use_vision:
        return extract_odds_with_vision(image_path)
    else:
        return extract_odds_tesseract(image_path)

def extract_odds_tesseract(image_path: str):
    """
    Extrait les cotes et scores depuis une image de bookmaker via Tesseract.
    Version am√©lior√©e avec meilleure stabilit√© OCR et distinction 0/O, 1/I.
    Compatible avec l'API existante.
    """
    try:
        logger.info("üîç D√©but de l'extraction OCR am√©lior√©e...")
        
        # Obtenir toutes les versions preprocessed
        versions = preprocess_image(image_path)
        
        all_texts = []
        
        # OCR sur chaque version
        for img_name, cv_img in versions:
            logger.info(f"üì∏ OCR sur version: {img_name}")
            try:
                # Convertir numpy array en PIL Image
                pil_img = Image.fromarray(cv_img)
                
                # Utiliser PSM 11 (sparse text) pour boutons isol√©s si c'est une version sp√©ciale
                if img_name in ["red_channel_inv", "green_thresh", "green_buttons"]:
                    text = pytesseract.image_to_string(pil_img, lang=LANGS, config="--psm 11")
                else:
                    text = pytesseract.image_to_string(pil_img, lang=LANGS, config="--psm 6")
                
                if text.strip():
                    all_texts.append((img_name, text))
                    logger.info(f"‚úÖ {img_name}: {len(text)} caract√®res extraits")
            except Exception as e:
                logger.warning(f"Erreur OCR {img_name}: {e}")
        
        logger.info(f"‚úÖ {len(all_texts)} textes extraits au total")
        
        # DEBUG: Log √©tape OCR
        log_ocr_step("Extraction OCR compl√©t√©e", len(all_texts))
        
        # Afficher un √©chantillon du meilleur texte
        if all_texts:
            longest_text = max(all_texts, key=lambda x: len(x[1]))
            logger.info(f"=== MEILLEUR TEXTE OCR ({longest_text[0]}) ===\n{longest_text[1][:300]}\n=== FIN ===")
        
        # Extraire les scores et cotes
        scores = []
        seen_scores = set()
        
        for source_name, text in all_texts:
            # Normalisation du texte
            text_normalized = text.replace("O", "0").replace("I", "1").replace("l", "1")
            text_normalized = text_normalized.replace(",", ".")
            
            # Pattern 1: Score suivi de cote - ex: "1-0 15.20"
            pattern1 = re.compile(r"(\d+[-:]\d+)\s*([0-9]+\.[0-9]+)")
            for match in pattern1.finditer(text_normalized):
                score = clean_score(match.group(1))
                
                if re.match(r'^\d{1,2}-\d{1,2}$', score):  # Format valide
                    odds_str = match.group(2)
                    try:
                        odds = float(odds_str)
                        if odds > 100:  # Probablement un pourcentage
                            continue
                        if 1.01 <= odds <= 100:
                            score_key = f"{score}_{odds}"
                            if score_key not in seen_scores:
                                scores.append({"score": score, "odds": odds})
                                seen_scores.add(score_key)
                                logger.info(f"‚úì [{source_name}] Pattern1 - {score} @ {odds}")
                    except ValueError:
                        continue
            
            # Pattern 2: Extraire tous les scores, puis toutes les cotes
            all_scores_in_text = []
            all_odds_in_text = []
            
            # Scores
            score_matches = re.findall(r"(\d+[-:]\d+)", text_normalized)
            for s in score_matches:
                score = clean_score(s)
                if re.match(r'^\d{1,2}-\d{1,2}$', score):
                    all_scores_in_text.append(score)
            
            # Cotes (nombres d√©cimaux entre 1.01 et 100)
            odds_matches = re.findall(r"([0-9]+\.[0-9]+)", text_normalized)
            for o in odds_matches:
                try:
                    odds_val = float(o)
                    if 1.01 <= odds_val <= 100:
                        all_odds_in_text.append(odds_val)
                except:
                    continue
            
            # NOUVEAU: Aussi chercher nombres ENTIERS comme cotes (ex: "13", "24")
            # Format Unibet avec gros chiffres
            integer_odds = re.findall(r"\b([1-9][0-9]?)\b", text_normalized)
            for o in integer_odds:
                try:
                    odds_val = float(o)
                    if 2 <= odds_val <= 100:  # Cotes enti√®res raisonnables
                        all_odds_in_text.append(odds_val)
                except:
                    continue
            
            logger.info(f"[{source_name}] Scores: {len(all_scores_in_text)}, Cotes: {len(all_odds_in_text)}")
            
            # Associer dans l'ordre
            min_len = min(len(all_scores_in_text), len(all_odds_in_text))
            for i in range(min_len):
                score = all_scores_in_text[i]
                odds = all_odds_in_text[i]
                score_key = f"{score}_{odds}"
                if score_key not in seen_scores:
                    scores.append({"score": score, "odds": odds})
                    seen_scores.add(score_key)
                    logger.info(f"‚úì [{source_name}] Pattern2 - {score} @ {odds}")
        
        # Chercher "Autre"
        combined_text = " ".join([t[1] for t in all_texts])
        for keyword in ["autre", "other", "any"]:
            other_match = re.search(rf"{keyword}\s*([0-9]+\.[0-9]+)", combined_text, re.IGNORECASE)
            if other_match:
                try:
                    odds = float(other_match.group(1))
                    if not any(s["score"] == "Autre" for s in scores):
                        scores.append({"score": "Autre", "odds": odds})
                        logger.info(f"‚úì Option 'Autre' @ {odds}")
                        break
                except:
                    pass
        
        # D√©dupliquer et valider
        final_scores = []
        score_odds_map = {}
        
        for item in scores:
            score = item["score"]
            odds = item["odds"]
            
            # Validation des scores
            if score != "Autre":
                parts = score.split('-')
                if len(parts) == 2:
                    try:
                        home, away = int(parts[0]), int(parts[1])
                        
                        # Rejeter les scores impossibles
                        if home < 0 or away < 0:
                            logger.warning(f"‚ö†Ô∏è Score rejet√© (n√©gatif): {score}")
                            continue
                        if home > 9 or away > 9:
                            logger.warning(f"‚ö†Ô∏è Score rejet√© (>9 buts): {score}")
                            continue
                        if abs(home - away) > 4:
                            logger.warning(f"‚ö†Ô∏è Score rejet√© (diff√©rence >4): {score}")
                            continue
                    except:
                        logger.warning(f"‚ö†Ô∏è Score rejet√© (format invalide): {score}")
                        continue
            
            if score not in score_odds_map:
                score_odds_map[score] = []
            score_odds_map[score].append(odds)
        
        # Prendre la cote m√©diane pour chaque score
        for score, odds_list in score_odds_map.items():
            odds_list.sort()
            median_odds = odds_list[len(odds_list) // 2]
            final_scores.append({"score": score, "odds": median_odds})
        
        logger.info(f"üìä TOTAL FINAL: {len(final_scores)} scores uniques extraits")
        
        # DEBUG: Log scores finaux extraits
        log_ocr_step("Scores valid√©s et filtr√©s", len(final_scores), final_scores)
        
        return final_scores
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'extraction OCR: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return []